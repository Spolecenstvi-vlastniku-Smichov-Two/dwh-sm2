import subprocess
import pandas as pd
from datetime import datetime, timedelta
import io
import os

ORG = os.environ["INFLUX_ORG"]
TOKEN = os.environ["INFLUX_TOKEN"]
URL = os.environ["INFLUX_URL"]
BUCKET = "sensor_data"
MEASUREMENT = "nonadditive"

def get_time_query(extreme: str):
    desc = "desc: true" if extreme == "max" else "desc: false"
    query = f'''
from(bucket: "{BUCKET}")
  |> range(start: -100y)
  |> filter(fn: (r) => r._measurement == "{MEASUREMENT}")
  |> sort(columns: ["_time"], {desc})
  |> limit(n:1)
'''
    print(f"\nğŸ”¹ SpouÅ¡tÃ­m dotaz pro {extreme} Äas:\n{query}")

    result = subprocess.run([
        "influx", "query",
        "--org", ORG,
        "--token", TOKEN,
        "--host", URL,
        "--raw",  # zachovÃ¡ hlaviÄky
        "--execute", query
    ], capture_output=True, text=True)

    if result.returncode != 0 or not result.stdout.strip():
        print(f"âš ï¸ Å½Ã¡dnÃ¡ data pro {extreme} Äas. PravdÄ›podobnÄ› bucket prÃ¡zdnÃ½.")
        return None

    # Debug: vÃ½pis prvnÃ­ch 10 Å™Ã¡dkÅ¯ CLI
    print(f"\nğŸ”¹ Debug CLI ({extreme} Äas) - prvnÃ­ch 10 Å™Ã¡dkÅ¯:")
    print("\n".join(result.stdout.splitlines()[:10]))

    # PÅ™eskoÄÃ­me prvnÃ­ 3 Å™Ã¡dky (#group, #datatype, #default)
    df = pd.read_csv(io.StringIO(result.stdout), skiprows=3)
    if df.empty:
        print(f"âš ï¸ Pandas naÄetl prÃ¡zdnÃ½ DataFrame pro {extreme} Äas.")
        return None

    print(f"\nğŸ”¹ NÃ¡hled DataFrame ({extreme} Äas):")
    print(df.head())

    if "_time" not in df.columns:
        print(f"âš ï¸ Sloupec _time nebyl nalezen v datech {extreme} Äas.")
        return None

    return pd.to_datetime(df["_time"].iloc[0])

start_ts = get_time_query("min")
end_ts = get_time_query("max")

if start_ts is None or end_ts is None:
    print("â„¹ï¸ Raw bucket je prÃ¡zdnÃ½, export se pÅ™eskoÄÃ­.")
    exit(0)

print(f"\nâœ… DetekovÃ¡n ÄasovÃ½ rozsah dat: {start_ts} â†’ {end_ts}")

start = start_ts.replace(day=1)
end = end_ts.replace(day=1)

current = start
generated_files = []

while current <= end:
    next_month = (current.replace(day=28) + timedelta(days=4)).replace(day=1)
    month_str = current.strftime("%Y-%m")
    output_file = f"gdrive/nonadditive_{month_str}.annotated.csv"

    flux = f'''
from(bucket: "{BUCKET}")
  |> range(start: {current.isoformat()}Z, stop: {next_month.isoformat()}Z)
  |> filter(fn: (r) => r._measurement == "{MEASUREMENT}")
'''
    with open("temp_raw_export.flux", "w") as f:
        f.write(flux)

    print(f"\nğŸ“¤ Exportuji RAW {month_str} â†’ {output_file}")
    with open(output_file, "w") as out:
        subprocess.run([
            "influx", "query",
            "--org", ORG,
            "--token", TOKEN,
            "--host", URL,
            "--file", "temp_raw_export.flux",
            "--raw",
            "--hide-headers"  # ÄistÃ½ CSV export pro dalÅ¡Ã­ import
        ], stdout=out, check=True)

    # Debug: ukÃ¡zka exportovanÃ©ho souboru
    with open(output_file, encoding="utf-8") as f:
        print(f"\nğŸ“„ NÃ¡hled souboru {output_file}:")
        for i in range(10):
            line = f.readline()
            if not line:
                break
            print(line.strip())

    generated_files.append(output_file)
    current = next_month

# Upload na Google Drive
print("\nâ˜ï¸ Upload raw exportÅ¯ na Google Drive")
subprocess.run([
    "rclone", "copy", "gdrive/", "sm2drive:Influx/", "--include", "nonadditive_*.annotated.csv"
], check=True)

print("\nâœ… Export raw dat dokonÄen.")
print("ğŸ“¦ ExportovanÃ© soubory:")
for file in generated_files:
    print("  ", file)
