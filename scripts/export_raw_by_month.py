import subprocess
import pandas as pd
from datetime import datetime, timedelta
import io
import os

ORG = os.environ["INFLUX_ORG"]
TOKEN = os.environ["INFLUX_TOKEN"]
URL = os.environ["INFLUX_URL"]
BUCKET = "sensor_data"
MEASUREMENT = "nonadditive"

def run_flux_query(flux_query: str, debug_label: str):
    """SpustÃ­ Flux dotaz pÅ™es doÄasnÃ½ .flux soubor a vrÃ¡tÃ­ surovÃ½ vÃ½stup CLI."""
    filename = f"temp_query_{debug_label}.flux"
    with open(filename, "w") as f:
        f.write(flux_query)

    print(f"\nğŸ”¹ SpouÅ¡tÃ­m Flux dotaz ({debug_label}):\n{flux_query}")

    result = subprocess.run([
        "influx", "query",
        "--org", ORG,
        "--token", TOKEN,
        "--host", URL,
        "--raw",
        "--file", filename
    ], capture_output=True, text=True)

    if result.returncode != 0:
        print(f"âŒ Chyba pÅ™i dotazu ({debug_label}):")
        print(result.stderr)
        return None

    output = result.stdout.strip()
    if not output:
        print(f"âš ï¸ Dotaz ({debug_label}) vrÃ¡til prÃ¡zdnÃ½ vÃ½stup.")
        return None

    print(f"\nğŸ”¹ SurovÃ½ vÃ½stup CLI ({debug_label}) - prvnÃ­ch 10 Å™Ã¡dkÅ¯:")
    print("\n".join(output.splitlines()[:10]))
    return output

def parse_influx_csv(raw_output: str, label: str):
    """OdstranÃ­ 3 hlaviÄkovÃ© Å™Ã¡dky a vrÃ¡tÃ­ Pandas DataFrame."""
    lines = raw_output.splitlines()
    if len(lines) <= 3:
        print(f"âš ï¸ VÃ½stup pro {label} obsahuje mÃ©nÄ› neÅ¾ 4 Å™Ã¡dky.")
        return None

    csv_clean = "\n".join(lines[3:])
    df = pd.read_csv(io.StringIO(csv_clean))
    print(f"\nğŸ”¹ NÃ¡hled DataFrame ({label}):")
    print(df.head())

    if "_time" not in df.columns:
        print(f"âš ï¸ Sloupec _time nebyl nalezen v datech {label}.")
        return None
    return df

def get_time_query(extreme: str):
    """VrÃ¡tÃ­ min/max Äas z bucketu."""
    desc = "desc: true" if extreme == "max" else "desc: false"
    flux_query = f'''
from(bucket: "{BUCKET}")
  |> range(start: -100y)
  |> filter(fn: (r) => r._measurement == "{MEASUREMENT}")
  |> group(columns: [])
  |> sort(columns: ["_time"], {desc})
  |> limit(n:1)
'''

    raw_output = run_flux_query(flux_query, f"{extreme}_time")
    if not raw_output:
        print(f"âš ï¸ Å½Ã¡dnÃ¡ data pro {extreme} Äas. PravdÄ›podobnÄ› bucket prÃ¡zdnÃ½.")
        return None

    df = parse_influx_csv(raw_output, f"{extreme}_time")
    if df is None or df.empty:
        print(f"âš ï¸ NepodaÅ™ilo se naÄÃ­st DataFrame pro {extreme} Äas.")
        return None

    return pd.to_datetime(df["_time"].iloc[0])

# --- HlavnÃ­ logika skriptu ---

start_ts = get_time_query("min")
end_ts = get_time_query("max")

if start_ts is None or end_ts is None:
    print("â„¹ï¸ Raw bucket je prÃ¡zdnÃ½, export se pÅ™eskoÄÃ­.")
    exit(0)

print(f"\nâœ… DetekovÃ¡n ÄasovÃ½ rozsah dat: {start_ts} â†’ {end_ts}")

# Export po mÄ›sÃ­cÃ­ch
start = start_ts.replace(day=1)
end = end_ts.replace(day=1)

current = start
generated_files = []

while current <= end:
    next_month = (current.replace(day=28) + timedelta(days=4)).replace(day=1)
    month_str = current.strftime("%Y-%m")
    output_file = f"gdrive/nonadditive_{month_str}.annotated.csv"

    flux_export = f'''
from(bucket: "{BUCKET}")
  |> range(start: {current.isoformat()}Z, stop: {next_month.isoformat()}Z)
  |> filter(fn: (r) => r._measurement == "{MEASUREMENT}")
'''

    raw_output = run_flux_query(flux_export, f"export_{month_str}")
    if not raw_output:
        print(f"âš ï¸ Å½Ã¡dnÃ¡ data k exportu pro mÄ›sÃ­c {month_str}, pÅ™eskoÄeno.")
        current = next_month
        continue

    # UloÅ¾Ã­me ÄistÃ© CSV bez hlaviÄek pro snadnÃ½ reimport
    with open(output_file, "w", encoding="utf-8") as f:
        lines = raw_output.splitlines()
        # PonechÃ¡me annotated CSV pro dalÅ¡Ã­ import do Influxu
        f.write("\n".join(lines))

    print(f"\nğŸ“¤ Soubor exportovÃ¡n: {output_file}")
    with open(output_file, encoding="utf-8") as f:
        print(f"ğŸ“„ NÃ¡hled {output_file}:")
        for i in range(10):
            line = f.readline()
            if not line:
                break
            print(line.strip())

    generated_files.append(output_file)
    current = next_month

# Upload na Google Drive
print("\nâ˜ï¸ Upload raw exportÅ¯ na Google Drive")
subprocess.run([
    "rclone", "copy", "gdrive/", "sm2drive:Influx/", "--include", "nonadditive_*.annotated.csv"
], check=True)

print("\nâœ… Export raw dat dokonÄen.")
print("ğŸ“¦ ExportovanÃ© soubory:")
for file in generated_files:
    print("  ", file)
