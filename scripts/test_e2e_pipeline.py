#!/usr/bin/env python3
"""
End-to-End Pipeline Test Script for SM2 Data Warehouse

Simuluje cel√Ω workflow lok√°lnƒõ:
1. P≈ô√≠prava testovac√≠ch dat
2. F√°ze 1: Schema validation + Data-driven ingest
3. dbt transformace
4. InfluxDB import a agregace
5. Vytvo≈ôen√≠ ve≈ôejn√©ho datasetu

Pou≈æit√≠:
    python3 scripts/test_e2e_pipeline.py [--with-real-data] [--skip-influx]
"""

import argparse
import subprocess
import sys
import os
import shutil
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime, timedelta
import tempfile
import json

class E2ETestRunner:
    def __init__(self, use_real_data=False, skip_influx=False):
        self.use_real_data = use_real_data
        self.skip_influx = skip_influx
        self.test_dir = Path("./test_e2e")
        self.gdrive_dir = Path("./gdrive")
        self.public_dir = Path("./public")
        
    def setup_test_environment(self):
        """P≈ô√≠prava testovac√≠ho prost≈ôed√≠"""
        print("üîß P≈ô√≠prava testovac√≠ho prost≈ôed√≠...")
        
        # Vytvo≈ôen√≠ testovac√≠ch adres√°≈ô≈Ø
        self.test_dir.mkdir(exist_ok=True)
        self.gdrive_dir.mkdir(exist_ok=True)
        self.public_dir.mkdir(exist_ok=True)
        
        # Backup existuj√≠c√≠ch dat
        if (self.gdrive_dir / "fact.csv").exists():
            shutil.copy(self.gdrive_dir / "fact.csv", self.test_dir / "fact.csv.backup")
            print("  ‚úÖ Z√°lohov√°n√≠ existuj√≠c√≠ch dat")
        
        print("  ‚úÖ Testovac√≠ prost≈ôed√≠ p≈ôipraveno")
    
    def create_test_data(self):
        """Vytvo≈ôen√≠ testovac√≠ch dat"""
        print("üìä Vytv√°≈ôen√≠ testovac√≠ch dat...")
        
        if self.use_real_data:
            print("  üåê Stahov√°n√≠ re√°ln√Ωch dat z Google Drive...")
            try:
                # Sta≈æen√≠ re√°ln√Ωch dat
                subprocess.run([
                    "rclone", "copy", 
                    "sm2drive:Vzduchotechnika/Latest/Upload", 
                    str(self.test_dir / "ventilation"),
                    "--include", "Graph*.csv",
                    "--max-size", "50M"  # Omezen√≠ velikosti pro test
                ], check=True, capture_output=True)
                
                subprocess.run([
                    "rclone", "copy",
                    "sm2drive:Indoor/Latest/Upload",
                    str(self.test_dir / "indoor"),
                    "--include", "ThermoProSensor_export*.csv",
                    "--max-size", "50M"
                ], check=True, capture_output=True)
                
                print("  ‚úÖ Re√°ln√° data sta≈æena")
            except subprocess.CalledProcessError as e:
                print(f"  ‚ö†Ô∏è  Chyba p≈ôi stahov√°n√≠ re√°ln√Ωch dat: {e}")
                print("  üîÑ P≈ôep√≠n√°m na syntetick√° data...")
                self._create_synthetic_data()
        else:
            self._create_synthetic_data()
    
    def _create_synthetic_data(self):
        """Vytvo≈ôen√≠ syntetick√Ωch testovac√≠ch dat"""
        print("  üß™ Vytv√°≈ôen√≠ syntetick√Ωch dat...")
        
        # Ventilation data (wide format)
        ventilation_dir = self.test_dir / "ventilation"
        ventilation_dir.mkdir(exist_ok=True)
        
        # Generov√°n√≠ 30 dn√≠ dat s hodinov√Ωmi z√°znamy
        start_date = datetime.now() - timedelta(days=30)
        dates = pd.date_range(start_date, periods=30*24, freq='h')
        
        ventilation_data = {
            'date': dates.strftime('%Y-%m-%d %H:%M:%S'),
            'KOT1/Teplota venkovn√≠': [15 + 10 * np.sin(i/24 * 2 * np.pi) + np.random.normal(0, 2) for i in range(len(dates))],
            'KOT1/Vlhkost venkovn√≠': [60 + 20 * np.sin(i/24 * 2 * np.pi + 1) + np.random.normal(0, 5) for i in range(len(dates))],
            'KOT1/Rychlost vƒõtru': [5 + 3 * np.random.random() for _ in range(len(dates))],
            'KOT1/Tlak': [1013 + np.random.normal(0, 10) for _ in range(len(dates))]
        }
        
        ventilation_df = pd.DataFrame(ventilation_data)
        ventilation_df.to_csv(ventilation_dir / "Graph_test_data.csv", index=False)
        
        # Indoor data (narrow format)
        indoor_dir = self.test_dir / "indoor"
        indoor_dir.mkdir(exist_ok=True)
        
        indoor_data = []
        locations = ['Living Room', 'Bedroom', 'Kitchen', 'Bathroom']
        
        for date in dates[::6]:  # Ka≈æd√Ωch 6 hodin
            for location in locations:
                # Teplota
                indoor_data.append({
                    'time': date.strftime('%Y-%m-%d %H:%M:%S'),
                    'location': location,
                    'measurement': 'temperature',
                    'data_key': 'temperature',
                    'data_value': 20 + np.random.normal(0, 2)
                })
                # Vlhkost
                indoor_data.append({
                    'time': date.strftime('%Y-%m-%d %H:%M:%S'),
                    'location': location,
                    'measurement': 'humidity',
                    'data_key': 'humidity',
                    'data_value': 45 + np.random.normal(0, 5)
                })
        
        indoor_df = pd.DataFrame(indoor_data)
        indoor_df.to_csv(indoor_dir / "ThermoProSensor_export_test.csv", index=False)
        
        print(f"  ‚úÖ Syntetick√° data vytvo≈ôena:")
        print(f"    - Ventilation: {len(ventilation_df)} ≈ô√°dk≈Ø")
        print(f"    - Indoor: {len(indoor_df)} ≈ô√°dk≈Ø")
    
    def test_phase1_validation(self):
        """Test Phase 1: Schema validation a data-driven ingest"""
        print("üîç Test Phase 1: Schema validation + Data-driven ingest...")
        
        # Kop√≠rov√°n√≠ testovac√≠ch dat do spr√°vn√Ωch lokac√≠
        if (self.test_dir / "ventilation").exists():
            shutil.copytree(self.test_dir / "ventilation", self.gdrive_dir / "ventilation", dirs_exist_ok=True)
        if (self.test_dir / "indoor").exists():
            shutil.copytree(self.test_dir / "indoor", self.gdrive_dir / "indoor", dirs_exist_ok=True)
        
        # Vytvo≈ôen√≠ dummy fact soubor≈Ø pro validaci (raw form√°ty)
        if (self.test_dir / "ventilation" / "Graph_test_data.csv").exists():
            shutil.copy(self.test_dir / "ventilation" / "Graph_test_data.csv", self.gdrive_dir / "merged.csv")
        if (self.test_dir / "indoor" / "ThermoProSensor_export_test.csv").exists():
            # P≈ôevod na spr√°vn√Ω form√°t pro all_sensors_merged.csv
            indoor_df = pd.read_csv(self.test_dir / "indoor" / "ThermoProSensor_export_test.csv")
            
            # Kontrola, ≈æe m√°me data
            if len(indoor_df) > 0:
                # P≈ôevod z narrow na wide form√°t pro indoor merge
                indoor_wide = indoor_df.pivot_table(
                    index=['time'], 
                    columns=['data_key'], 
                    values='data_value', 
                    aggfunc='first'
                ).reset_index()
                indoor_wide.columns.name = None
                indoor_wide = indoor_wide.rename(columns={
                    'time': 'Datetime',
                    'temperature': 'Temperature_Celsius',
                    'humidity': 'Relative_Humidity(%)'
                })
                indoor_wide['Location'] = 'Living Room'
                indoor_wide.to_csv(self.gdrive_dir / "all_sensors_merged.csv", index=False)
            else:
                # Vytvo≈ôen√≠ pr√°zdn√©ho souboru s hlaviƒçkou
                empty_indoor = pd.DataFrame(columns=['Datetime', 'Temperature_Celsius', 'Relative_Humidity(%)', 'Location'])
                empty_indoor.to_csv(self.gdrive_dir / "all_sensors_merged.csv", index=False)
        
        # Vytvo≈ôen√≠ dummy soubor≈Ø pro dbt modely
        self._create_dummy_dbt_files()
        
        # Test 1: Data-driven ingest
        print("  1Ô∏è‚É£ Test data-driven ingest...")
        try:
            result = subprocess.run([
                "python3", "scripts/ingest_data.py"
            ], capture_output=True, text=True, timeout=60)
            
            if result.returncode == 0:
                print("    ‚úÖ Data-driven ingest √∫spƒõ≈°n√Ω")
            elif "rclone.conf" in result.stderr or "didn't find section in config file" in result.stderr:
                print("    ‚ö†Ô∏è  Data-driven ingest selhal: rclone nen√≠ nakonfigurov√°n (oƒçek√°v√°no v testu)")
            else:
                print(f"    ‚ö†Ô∏è  Data-driven ingest selhal: {result.stderr.strip()}")
                if result.stdout.strip():
                    print(f"    üìÑ Stdout: {result.stdout.strip()}")
        except Exception as e:
            print(f"    ‚ö†Ô∏è  Chyba p≈ôi ingest testu: {e}")
        
        # Test 2: Schema validation
        print("  2Ô∏è‚É£ Test schema validation...")
        try:
            result = subprocess.run([
                "python3", "scripts/validate_schema.py"
            ], capture_output=True, text=True, timeout=30)
            
            if result.returncode == 0:
                print("    ‚úÖ Schema validation √∫spƒõ≈°n√°")
            else:
                print(f"    ‚ö†Ô∏è  Schema validation selhala: {result.stderr.strip()}")
                if result.stdout.strip():
                    print(f"    üìÑ Stdout: {result.stdout.strip()}")
        except Exception as e:
            print(f"    ‚ö†Ô∏è  Chyba p≈ôi schema validation: {e}")
        
        # Test 3: Quality checks
        print("  3Ô∏è‚É£ Test quality checks...")
        try:
            result = subprocess.run([
                "python3", "scripts/quality_checks.py"
            ], capture_output=True, text=True, timeout=30)
            
            if result.returncode == 0:
                print("    ‚úÖ Quality checks √∫spƒõ≈°n√©")
            else:
                print(f"    ‚ö†Ô∏è  Quality checks selhaly: {result.stderr.strip()}")
                if result.stdout.strip():
                    print(f"    üìÑ Stdout: {result.stdout.strip()}")
        except Exception as e:
            print(f"    ‚ö†Ô∏è  Chyba p≈ôi quality checks: {e}")
    
    def test_data_merging(self):
        """Test sluƒçov√°n√≠ dat (simulace refresh workflow)"""
        print("üîÑ Test sluƒçov√°n√≠ dat...")
        
        # Simulace ventilation merge (csvkit)
        print("  1Ô∏è‚É£ Test ventilation merge...")
        ventilation_files = list((self.gdrive_dir / "ventilation").glob("Graph*.csv"))
        if ventilation_files:
            try:
                # Pou≈æit√≠ csvstack pro slouƒçen√≠ soubor≈Ø
                with open(self.gdrive_dir / "merged.csv", "w") as outfile:
                    subprocess.run([
                        "csvstack"
                    ] + [str(f) for f in ventilation_files], 
                    stdout=outfile, check=True)
                print("    ‚úÖ Ventilation merge √∫spƒõ≈°n√Ω")
            except Exception as e:
                print(f"    ‚ö†Ô∏è  Ventilation merge selhal: {e}")
        
        # Simulace indoor merge (bash script)
        print("  2Ô∏è‚É£ Test indoor merge...")
        try:
            result = subprocess.run([
                "bash", "scripts/indoor_merge_all_sensors.sh"
            ], cwd=".", capture_output=True, text=True, timeout=60)
            
            if result.returncode == 0:
                print("    ‚úÖ Indoor merge √∫spƒõ≈°n√Ω")
            else:
                print(f"    ‚ö†Ô∏è  Indoor merge selhal: {result.stderr}")
        except Exception as e:
            print(f"    ‚ö†Ô∏è  Chyba p≈ôi indoor merge: {e}")
    
    def test_dbt_transformations(self):
        """Test dbt transformac√≠"""
        print("üèóÔ∏è  Test dbt transformac√≠...")
        
        # Test dbt parse
        print("  1Ô∏è‚É£ Test dbt parse...")
        try:
            result = subprocess.run([
                "dbt", "parse", "--profiles-dir", "/workspace"
            ], capture_output=True, text=True, timeout=30)
            
            if result.returncode == 0:
                print("    ‚úÖ dbt parse √∫spƒõ≈°n√Ω")
            else:
                print(f"    ‚ö†Ô∏è  dbt parse selhal: {result.stderr.strip()}")
                if result.stdout.strip():
                    print(f"    üìÑ Stdout: {result.stdout.strip()}")
        except Exception as e:
            print(f"    ‚ö†Ô∏è  Chyba p≈ôi dbt parse: {e}")
        
        # Test dbt seed
        print("  2Ô∏è‚É£ Test dbt seed...")
        try:
            result = subprocess.run([
                "dbt", "seed", "--profiles-dir", "/workspace"
            ], capture_output=True, text=True, timeout=60)
            
            if result.returncode == 0:
                print("    ‚úÖ dbt seed √∫spƒõ≈°n√Ω")
            else:
                print(f"    ‚ö†Ô∏è  dbt seed selhal: {result.stderr.strip()}")
                if result.stdout.strip():
                    print(f"    üìÑ Stdout: {result.stdout.strip()}")
        except Exception as e:
            print(f"    ‚ö†Ô∏è  Chyba p≈ôi dbt seed: {e}")
        
        # Test dbt run
        print("  3Ô∏è‚É£ Test dbt run...")
        try:
            result = subprocess.run([
                "dbt", "run", "--profiles-dir", "/workspace"
            ], capture_output=True, text=True, timeout=120)
            
            if result.returncode == 0:
                print("    ‚úÖ dbt run √∫spƒõ≈°n√Ω")
                # Kontrola v√Ωstupn√≠ch soubor≈Ø
                expected_files = ["fact.csv", "fact_indoor_temperature.csv", "fact_indoor_humidity.csv"]
                for file in expected_files:
                    if (self.gdrive_dir / file).exists():
                        print(f"      ‚úÖ {file} vytvo≈ôen")
                    else:
                        print(f"      ‚ùå {file} chyb√≠")
            else:
                print(f"    ‚ö†Ô∏è  dbt run selhal: {result.stderr.strip()}")
                if result.stdout.strip():
                    print(f"    üìÑ Stdout: {result.stdout.strip()}")
        except Exception as e:
            print(f"    ‚ö†Ô∏è  Chyba p≈ôi dbt run: {e}")
    
    def test_influxdb_pipeline(self):
        """Test InfluxDB pipeline (pokud nen√≠ p≈ôeskoƒçen)"""
        if self.skip_influx:
            print("‚è≠Ô∏è  InfluxDB pipeline p≈ôeskoƒçen")
            return
        
        print("üìä Test InfluxDB pipeline...")
        
        # Kontrola InfluxDB dostupnosti
        print("  1Ô∏è‚É£ Test InfluxDB p≈ôipojen√≠...")
        try:
            # Zkus√≠me nejprve devcontainer URL, pak localhost
            result = subprocess.run([
                "curl", "-f", "http://influxdb:8086/health"
            ], capture_output=True, text=True, timeout=10)
            
            if result.returncode == 0:
                print("    ‚úÖ InfluxDB dostupn√Ω (devcontainer)")
            else:
                # Fallback na localhost
                result = subprocess.run([
                    "curl", "-f", "http://localhost:8086/health"
                ], capture_output=True, text=True, timeout=10)
                
                if result.returncode == 0:
                    print("    ‚úÖ InfluxDB dostupn√Ω (localhost)")
                else:
                    print("    ‚ö†Ô∏è  InfluxDB nedostupn√Ω na obou URL - p≈ôeskakujem Docker start v devcontaineru")
                    return
        except Exception as e:
            print(f"    ‚ö†Ô∏è  Chyba p≈ôi kontrole InfluxDB: {e}")
            return
        
        # Test prepare annotated CSV
        print("  2Ô∏è‚É£ Test prepare annotated CSV...")
        try:
            result = subprocess.run([
                "python3", "scripts/prepare_annotated_csv.py"
            ], capture_output=True, text=True, timeout=60)
            
            if result.returncode == 0:
                print("    ‚úÖ Annotated CSV p≈ôipraven")
            else:
                print(f"    ‚ö†Ô∏è  Prepare annotated CSV selhal: {result.stderr}")
        except Exception as e:
            print(f"    ‚ö†Ô∏è  Chyba p≈ôi prepare annotated CSV: {e}")
        
        # Test export aggregated
        print("  3Ô∏è‚É£ Test export aggregated...")
        try:
            result = subprocess.run([
                "python3", "scripts/export_aggregated_to_csv.py"
            ], capture_output=True, text=True, timeout=120)
            
            if result.returncode == 0:
                print("    ‚úÖ Export aggregated √∫spƒõ≈°n√Ω")
            else:
                print(f"    ‚ö†Ô∏è  Export aggregated selhal: {result.stderr}")
        except Exception as e:
            print(f"    ‚ö†Ô∏è  Chyba p≈ôi export aggregated: {e}")
    
    def _start_influxdb_docker(self):
        """Spu≈°tƒõn√≠ InfluxDB v Dockeru"""
        try:
            subprocess.run([
                "docker", "run", "-d", "--name", "influxdb-test",
                "-p", "8086:8086",
                "-e", "DOCKER_INFLUXDB_INIT_MODE=setup",
                "-e", "DOCKER_INFLUXDB_INIT_USERNAME=dev",
                "-e", "DOCKER_INFLUXDB_INIT_PASSWORD=devpassword",
                "-e", "DOCKER_INFLUXDB_INIT_ORG=dev",
                "-e", "DOCKER_INFLUXDB_INIT_BUCKET=sensor_data",
                "-e", "DOCKER_INFLUXDB_INIT_ADMIN_TOKEN=devtoken",
                "influxdb:2.7"
            ], check=True, capture_output=True)
            
            # ƒåek√°n√≠ na spu≈°tƒõn√≠
            import time
            time.sleep(10)
            print("    ‚úÖ InfluxDB Docker spu≈°tƒõn")
        except Exception as e:
            print(f"    ‚ùå Chyba p≈ôi spu≈°tƒõn√≠ InfluxDB Docker: {e}")
    
    def test_public_dataset_build(self):
        """Test vytvo≈ôen√≠ ve≈ôejn√©ho datasetu"""
        print("üì¶ Test vytvo≈ôen√≠ ve≈ôejn√©ho datasetu...")
        
        # Vytvo≈ôen√≠ dummy agregovan√Ωch soubor≈Ø pokud neexistuj√≠
        if not list(self.gdrive_dir.glob("*hourly.csv")):
            print("  üîß Vytv√°≈ôen√≠ dummy agregovan√Ωch soubor≈Ø...")
            self._create_dummy_aggregated_files()
        
        try:
            result = subprocess.run([
                "python3", "scripts/build_public_dataset.py"
            ], capture_output=True, text=True, timeout=120)
            
            if result.returncode == 0:
                print("    ‚úÖ Public dataset build √∫spƒõ≈°n√Ω")
                
                # Kontrola v√Ωstupn√≠ch soubor≈Ø
                expected_files = [
                    "sm2_public_dataset.csv.gz",
                    "sm2_public_dataset.parquet",
                    "README.md",
                    "schema.json",
                    "LICENSE"
                ]
                
                for file in expected_files:
                    if (self.public_dir / file).exists():
                        print(f"      ‚úÖ {file} vytvo≈ôen")
                    else:
                        print(f"      ‚ùå {file} chyb√≠")
            else:
                print(f"    ‚ö†Ô∏è  Public dataset build selhal: {result.stderr}")
        except Exception as e:
            print(f"    ‚ö†Ô∏è  Chyba p≈ôi public dataset build: {e}")
    
    def _create_dummy_dbt_files(self):
        """Vytvo≈ôen√≠ dummy soubor≈Ø pro dbt modely"""
        # Dummy indoor temperature data
        indoor_temp_data = {
            'time': pd.date_range(datetime.now() - timedelta(days=7), periods=7*24, freq='h'),
            'location': ['Living Room'] * (7*24),
            'data_key': ['temperature'] * (7*24),
            'data_value': [20 + np.random.normal(0, 2) for _ in range(7*24)]
        }
        indoor_temp_df = pd.DataFrame(indoor_temp_data)
        indoor_temp_df.to_csv(self.gdrive_dir / "fact_indoor_temperature.csv", index=False)
        
        # Dummy indoor humidity data
        indoor_hum_data = {
            'time': pd.date_range(datetime.now() - timedelta(days=7), periods=7*24, freq='h'),
            'location': ['Living Room'] * (7*24),
            'data_key': ['humidity'] * (7*24),
            'data_value': [45 + np.random.normal(0, 5) for _ in range(7*24)]
        }
        indoor_hum_df = pd.DataFrame(indoor_hum_data)
        indoor_hum_df.to_csv(self.gdrive_dir / "fact_indoor_humidity.csv", index=False)
        
        # Vytvo≈ôen√≠ dummy _original soubor≈Ø pro dbt UNION
        # fact_original.csv (ventilation historical data)
        ventilation_original_data = {
            'time': pd.date_range(datetime.now() - timedelta(days=60), periods=30, freq='D'),
            'location': ['outdoor'] * 30,
            'data_key': ['temperature'] * 30,
            'data_value': [10 + np.random.normal(0, 3) for _ in range(30)]
        }
        ventilation_original_df = pd.DataFrame(ventilation_original_data)
        ventilation_original_df.to_csv(self.gdrive_dir / "fact_original.csv", index=False)
        
        # fact_indoor_temperature_original.csv
        indoor_temp_original_data = {
            'time': pd.date_range(datetime.now() - timedelta(days=60), periods=30, freq='D'),
            'location': ['Living Room'] * 30,
            'data_key': ['temperature'] * 30,
            'data_value': [18 + np.random.normal(0, 2) for _ in range(30)]
        }
        indoor_temp_original_df = pd.DataFrame(indoor_temp_original_data)
        indoor_temp_original_df.to_csv(self.gdrive_dir / "fact_indoor_temperature_original.csv", index=False)
        
        # fact_indoor_humidity_original.csv
        indoor_hum_original_data = {
            'time': pd.date_range(datetime.now() - timedelta(days=60), periods=30, freq='D'),
            'location': ['Living Room'] * 30,
            'data_key': ['humidity'] * 30,
            'data_value': [40 + np.random.normal(0, 5) for _ in range(30)]
        }
        indoor_hum_original_df = pd.DataFrame(indoor_hum_original_data)
        indoor_hum_original_df.to_csv(self.gdrive_dir / "fact_indoor_humidity_original.csv", index=False)

    def _create_dummy_aggregated_files(self):
        """Vytvo≈ôen√≠ dummy agregovan√Ωch soubor≈Ø pro test"""
        current_month = datetime.now().strftime("%Y-%m")
        
        # Additive data
        additive_data = {
            'time': pd.date_range(datetime.now() - timedelta(days=30), periods=30*24, freq='h'),
            'location': ['outdoor'] * (30*24),
            'source': ['ventilation'] * (30*24),
            'measurement': ['energy'] * (30*24),
            'data_key': ['consumption'] * (30*24),
            'data_value': [np.random.random() * 100 for _ in range(30*24)]
        }
        
        additive_df = pd.DataFrame(additive_data)
        additive_df.to_csv(self.gdrive_dir / f"additive_{current_month}.hourly.csv", index=False)
        
        # Non-additive data
        nonadditive_data = {
            'time': pd.date_range(datetime.now() - timedelta(days=30), periods=30*24, freq='h'),
            'location': ['outdoor'] * (30*24),
            'source': ['ventilation'] * (30*24),
            'measurement': ['temperature'] * (30*24),
            'data_key': ['temperature'] * (30*24),
            'data_value': [15 + np.random.normal(0, 5) for _ in range(30*24)]
        }
        
        nonadditive_df = pd.DataFrame(nonadditive_data)
        nonadditive_df.to_csv(self.gdrive_dir / f"nonadditive_{current_month}.hourly.csv", index=False)
    
    def cleanup(self):
        """√öklid po testech"""
        print("üßπ √öklid testovac√≠ho prost≈ôed√≠...")
        
        # Obnoven√≠ z√°loh
        if (self.test_dir / "fact.csv.backup").exists():
            shutil.copy(self.test_dir / "fact.csv.backup", self.gdrive_dir / "fact.csv")
            print("  ‚úÖ Z√°lohy obnoveny")
        
        # Zastaven√≠ test InfluxDB
        try:
            subprocess.run([
                "docker", "stop", "influxdb-test"
            ], capture_output=True)
            subprocess.run([
                "docker", "rm", "influxdb-test"
            ], capture_output=True)
        except:
            pass
        
        # Smaz√°n√≠ testovac√≠ch soubor≈Ø
        if self.test_dir.exists():
            shutil.rmtree(self.test_dir)
            print("  ‚úÖ Testovac√≠ soubory smaz√°ny")
    
    def run_full_test(self):
        """Spu≈°tƒõn√≠ kompletn√≠ho end-to-end testu"""
        print("üöÄ Spou≈°t√≠m kompletn√≠ E2E test SM2 Data Pipeline")
        print("=" * 60)
        
        try:
            self.setup_test_environment()
            self.create_test_data()
            self.test_phase1_validation()
            self.test_data_merging()
            self.test_dbt_transformations()
            self.test_influxdb_pipeline()
            self.test_public_dataset_build()
            
            print("=" * 60)
            print("‚úÖ E2E test dokonƒçen √∫spƒõ≈°nƒõ!")
            
        except KeyboardInterrupt:
            print("\n‚ö†Ô∏è  Test p≈ôeru≈°en u≈æivatelem")
        except Exception as e:
            print(f"\n‚ùå E2E test selhal: {e}")
        finally:
            self.cleanup()

def main():
    parser = argparse.ArgumentParser(description="End-to-End test SM2 Data Pipeline")
    parser.add_argument("--with-real-data", action="store_true", 
                       help="Pou≈æ√≠t re√°ln√° data z Google Drive m√≠sto syntetick√Ωch")
    parser.add_argument("--skip-influx", action="store_true",
                       help="P≈ôeskoƒçit InfluxDB testy")
    
    args = parser.parse_args()
    
    # Kontrola z√°vislost√≠
    required_commands = ["python3", "dbt"]
    if not args.skip_influx:
        required_commands.append("curl")
    if args.with_real_data:
        required_commands.append("rclone")
    
    missing_commands = []
    for cmd in required_commands:
        try:
            subprocess.run([cmd, "--version"], capture_output=True, check=True)
        except (subprocess.CalledProcessError, FileNotFoundError):
            missing_commands.append(cmd)
    
    if missing_commands:
        print(f"‚ùå Chybƒõj√≠c√≠ z√°vislosti: {', '.join(missing_commands)}")
        print("Nainstalujte je p≈ôed spu≈°tƒõn√≠m testu.")
        sys.exit(1)
    
    # Kontrola pandas v devcontainer prost≈ôed√≠
    try:
        import pandas
        print("‚úÖ pandas dostupn√Ω")
    except ImportError:
        print("‚ùå pandas nen√≠ dostupn√Ω - nainstalujte: pip install pandas")
        sys.exit(1)
    
    # Spu≈°tƒõn√≠ testu
    runner = E2ETestRunner(
        use_real_data=args.with_real_data,
        skip_influx=args.skip_influx
    )
    runner.run_full_test()

if __name__ == "__main__":
    main()
