# scripts/export_aggregated_to_csv.py
import os
import subprocess
import pandas as pd
from pathlib import Path
from io import StringIO

# --- Konfigurace ---
ORG   = os.getenv("INFLUX_ORG", "ci-org")
TOKEN = os.getenv("INFLUX_TOKEN", "ci-secret-token")
HOST  = os.getenv("INFLUX_URL", "http://influxdb:8086")  # pou≈æijeme --host
BUCKET = "sensor_data"
EXPORT_DIR = "./gdrive"
GDRIVE_REMOTE = "sm2drive:Normalized"  # kam pushnout agregovan√© CSV

# SAFE MODE - ochrana proti p≈ôeps√°n√≠ produkƒçn√≠ch dat
SAFE_MODE = os.getenv("SAFE_MODE", "1")  # Default: bezpeƒçn√Ω re≈æim
TEST_MODE = os.getenv("TEST_MODE", "0")  # Explicitn√≠ test re≈æim

Path(EXPORT_DIR).mkdir(parents=True, exist_ok=True)

def run_query_file(flux_query: str, label: str) -> str | None:
    """Zap√≠≈°e flux do temp souboru a spust√≠ 'influx query --file'. Vrac√≠ stdout (CSV) nebo None."""
    tmp_path = Path(f"tmp_{label}.flux")
    tmp_path.write_text(flux_query, encoding="utf-8")

    print(f"\nüîπ Spou≈°t√≠m Flux ({label}) p≈ôes --file: {tmp_path}")
    print(flux_query.strip(), "\n")

    res = subprocess.run(
        [
            "influx", "query",
            "--org", ORG,
            "--token", TOKEN,
            "--host", HOST,
            "--raw",
            "--file", str(tmp_path),
        ],
        capture_output=True, text=True
    )

    print("üîç STATUS CODE:", res.returncode)
    if res.stderr.strip():
        print("‚ö†Ô∏è STDERR:", res.stderr.strip())
    head = "\n".join(res.stdout.splitlines()[:10])
    print("üìÑ STDOUT (prvn√≠ch 10 ≈ô√°dk≈Ø):\n" + head)

    if res.returncode != 0 or not res.stdout.strip():
        return None
    return res.stdout

def parse_influx_csv(csv_text: str) -> pd.DataFrame:
    """Naƒçte CSV z Influx CLI; koment√°≈ôe (#group/#datatype/#default) ignoruje."""
    try:
        df = pd.read_csv(StringIO(csv_text), comment="#")
        return df
    except Exception as e:
        print("‚ùå Chyba p≈ôi ƒçten√≠ CSV:", e)
        return pd.DataFrame()

def get_min_max_time(measurement: str) -> tuple[str | None, str | None]:
    """Zjist√≠ minim√°ln√≠ a maxim√°ln√≠ _time v bucketu pro dan√© measurement. Vrac√≠ ISO stringy."""
    print("üîπ Zji≈°≈•uji rozsah ƒças≈Ø...")

    q_min = f"""
from(bucket: "{BUCKET}")
  |> range(start: -100y)
  |> filter(fn: (r) => r._measurement == "{measurement}")
  |> keep(columns: ["_time"])
  |> sort(columns: ["_time"], desc: false)
  |> limit(n: 1)
"""
    q_max = f"""
from(bucket: "{BUCKET}")
  |> range(start: -100y)
  |> filter(fn: (r) => r._measurement == "{measurement}")
  |> keep(columns: ["_time"])
  |> sort(columns: ["_time"], desc: true)
  |> limit(n: 1)
"""

    out_min = run_query_file(q_min, f"{measurement}_min_time")
    out_max = run_query_file(q_max, f"{measurement}_max_time")
    if not out_min or not out_max:
        print("‚ö†Ô∏è Pr√°zdn√Ω v√Ωstup dotazu pro min/max ƒças.")
        return None, None

    df_min = parse_influx_csv(out_min)
    df_max = parse_influx_csv(out_max)

    if df_min.empty or df_max.empty or "_time" not in df_min.columns or "_time" not in df_max.columns:
        print("‚ö†Ô∏è ≈Ω√°dn√° data pro min/max ƒças.")
        return None, None

    min_time = str(df_min["_time"].iloc[0])
    max_time = str(df_max["_time"].iloc[0])
    print(f"‚úÖ Rozsah {measurement}: {min_time} ‚Üí {max_time}")
    return min_time, max_time

def clean_and_write_monthly(df: pd.DataFrame, measurement: str) -> list[str]:
    """P≈ôejmenuje sloupce, vybere po≈æadovan√© a ulo≈æ√≠ po mƒõs√≠c√≠ch."""
    if df.empty:
        return []

    # P≈ôejmenov√°n√≠ a v√Ωbƒõr sloupc≈Ø
    rename_map = {"_time": "time", "_value": "data_value", "_measurement": "measurement", "quantity": "data_key"}
    df = df.rename(columns=rename_map)
    needed = ["time", "location", "source", "measurement", "data_key", "data_value"]
    # nƒõkter√© zdroje nemus√≠ m√≠t v≈°echny tagy ‚Äì o≈°et≈ôit chybƒõj√≠c√≠:
    for col in needed:
        if col not in df.columns:
            df[col] = pd.NA
    df = df[needed].copy()

    # Rozdƒõlen√≠ po mƒõs√≠c√≠ch
    df["time"] = pd.to_datetime(df["time"], errors="coerce", utc=True)
    df = df.dropna(subset=["time"])
    if df.empty:
        return []

    df["year_month"] = df["time"].dt.strftime("%Y-%m")
    out_files: list[str] = []

    for ym, g in df.groupby("year_month"):
        g2 = g.drop(columns=["year_month"]).copy()
        fname = f"{measurement}_{ym}.hourly.csv"
        fpath = str(Path(EXPORT_DIR) / fname)
        g2.to_csv(fpath, index=False)
        print(f"‚úÖ Ulo≈æeno: {fpath}")

        # Upload na GDrive (pouze pokud nen√≠ SAFE_MODE)
        if SAFE_MODE == "1" and TEST_MODE != "1":
            print(f"üõ°Ô∏è  SAFE MODE: Upload p≈ôeskoƒçen pro {fname}")
        else:
            rc = subprocess.run(["rclone", "copyto", fpath, f"{GDRIVE_REMOTE}/{fname}"],
                                capture_output=True, text=True)
            if rc.returncode != 0:
                print(f"‚ö†Ô∏è Upload selhal pro {fname}: {rc.stderr.strip()}")
            else:
                print(f"‚òÅÔ∏è Upload hotov: {GDRIVE_REMOTE}/{fname}")

        out_files.append(fpath)

    return out_files

def export_measurement_hourly(measurement: str, fn: str) -> list[str]:
    """Agregace 1h pro dan√© measurement a ulo≈æen√≠ do mƒõs√≠ƒçn√≠ch CSV (ƒçist√© CSV)."""
    print(f"\nüì§ Agreguji '{measurement}' (fn: {fn}) ...")
    t_min, t_max = get_min_max_time(measurement)
    if not t_min or not t_max:
        print(f"‚ÑπÔ∏è Measurement '{measurement}' nem√° data ‚Äì p≈ôeskoƒçeno.")
        return []

    q = f"""
from(bucket: "{BUCKET}")
  |> range(start: time(v: "{t_min}"), stop: time(v: "{t_max}"))
  |> filter(fn: (r) => r._measurement == "{measurement}")
  |> aggregateWindow(every: 1h, fn: {fn}, createEmpty: false)
  |> keep(columns: ["_time","_value","_measurement","location","quantity","source"])
  |> yield(name: "hourly")
"""
    out = run_query_file(q, f"{measurement}_hourly")
    if not out:
        print(f"‚ö†Ô∏è ≈Ω√°dn√Ω v√Ωstup pro '{measurement}'.")
        return []

    df = parse_influx_csv(out)
    if df.empty or "_time" not in df.columns:
        print(f"‚ö†Ô∏è V√Ωsledn√Ω DataFrame pro '{measurement}' je pr√°zdn√Ω.")
        return []

    return clean_and_write_monthly(df, measurement)

def main():
    created: list[str] = []
    # additive -> sum, nonadditive -> mean
    created += export_measurement_hourly("additive", "sum")
    created += export_measurement_hourly("nonadditive", "mean")

    if not created:
        print("\n‚ÑπÔ∏è Nebyly vytvo≈ôeny ≈æ√°dn√© soubory k uploadu.")
    else:
        print(f"\n‚úÖ Hotovo. Vzniklo {len(created)} soubor≈Ø.")
        for p in created:
            print("  -", p)

if __name__ == "__main__":
    main()

