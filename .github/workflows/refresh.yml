name: refresh

on:
  push:
    branches:
      - main
  schedule:
    - cron: '0 0 * * *'
  workflow_dispatch:
    
env:
  DBT_PROFILES_DIR: ./

jobs:
  refresh:
    runs-on: ubuntu-latest

    permissions:
      contents: write
      actions: read
      packages: write

    steps:
      - name: Check out the repository
        uses: actions/checkout@master

      - name: Setup Rclone
        uses: AnimMouse/setup-rclone@v1
        with:
          rclone_config: ${{ secrets.RCLONE_CONFIG }}
        
      - name: Add Rclone service account file
        uses: AnimMouse/setup-rclone/service-account-file@v1
        with:
          service_account_filename: service-account-file.json
          service_account_file: ${{ secrets.SERVICE_ACCOUNT_FILE }} 

      - uses: actions/setup-python@master
        with:
          python-version: '3.12'

      - name: Upgrade pip
        run: python -m pip install --upgrade pip

      - run: rclone copy sm2drive:Vzduchotechnika/Model/ ./gdrive/

      - run: rclone copy sm2drive:Indoor/Model/ ./gdrive/

      - run: ls -l ./gdrive/

      - run: rclone copy sm2drive:Vzduchotechnika/Latest/Upload ./latest/

      - run: rclone copy sm2drive:Indoor/Latest/Upload ./latest/

      - name: Install csvkit
        run: pip install --upgrade csvkit

      - name: Merge valid Ventilation data
        run: |
          Item=0
          Files=""
          if find ./latest -maxdepth 1 -type f -name 'Graph*' | grep -q .; then
            for file in ./latest/Graph*; do
              Item=$((Item + 1))
              Files+="./latest/tmp${Item}.csv "
              echo "Processing $file"
              nb_of_cols=$(csvcut -n "$file" -d ';' | grep "[A-Za-a]" | wc -l)
              csvcut -c 1-"$nb_of_cols" "$file" -d ';' >  ./latest/tmp"$Item".csv
              date=$(tail "$file" | grep "00:00" | tail -n 1 | grep -Eo '[0-9]{2}.[0-9]{2}.[0-9]{4} [0-9]{2}:[0-9]{2}:[0-9]{2}' | sed -E 's/([0-9]{2}).([0-9]{2}).([0-9]{4})/\3-\2-\1/')
            done
            Files=${Files::-1}
            csvjoin --locale cs_CZ -c Date --outer ${Files} > ./gdrive/merged.csv
            echo "extdate=${date//[\ \:\-\;><\@\$\#\&\(\)\?\\\/\%]/_}" >> $GITHUB_ENV
          else
            echo "Date,KOT1/Teplota venkovnÃ­ (Â°C)" >  ./gdrive/merged.csv
          fi

      - name: Make indoor_merge_all_sensors.sh executable
        run: chmod +x ./scripts/indoor_merge_all_sensors.sh

      - name: Merge valid Indoor data
        run: ./scripts/indoor_merge_all_sensors.sh
          
      - run: ls -l ./gdrive/

      - name: Install dependencies
        run: |
          pip install --upgrade dbt-duckdb
          pip install --upgrade duckdb
          dbt deps

      - name: Lint with sqlfluff
        run: |
          pip install sqlfluff==$(pip index versions sqlfluff | grep -oP '\d+\.\d+\.\d+' | head -n 2 | tail -n 1)
          sqlfluff fix --dialect duckdb -v models/
          sqlfluff lint --dialect duckdb -v models/
    
          # Linting only modified models
          # git fetch origin main:main
          # git diff main --name-only --diff-filter=d | egrep '^models/.*sql$$' | xargs -r sqlfluff lint

      - name: Run dbt source freshness
        run: dbt source freshness

      - name: Run dbt seed
        run: dbt seed

      - name: Run dbt build
        id: run_dbt_build
        run: dbt build --select result:error+ source_status:fresher+ --defer --state docs
        continue-on-error: true

      - name: Full dbt build 
        if: steps.run_dbt_build.outcome != 'success'
        run: dbt build

      - name: Run docs generate
        run: dbt docs generate

      - name: Generate dbt docs
        run: |
          mkdir -p ${{ github.workspace }}/docs && cp ${{ github.workspace }}/target/*.json ${{ github.workspace }}/docs
          cp ${{ github.workspace }}/target/*.html ${{ github.workspace }}/docs
          cp ${{ github.workspace }}/target/*.gpickle ${{ github.workspace }}/docs

      - run: |
          if [[ -f "./fact.csv" ]]; then
              rclone copy ./fact.csv sm2drive:Vzduchotechnika/Model/
          else
              echo "fact.csv not found, skipping upload"
          fi
          if [[ -f "./fact_indoor_temperature.csv" ]]; then
              rclone copy ./fact_indoor_temperature.csv sm2drive:Indoor/Model/
          else
              echo "fact_indoor_temperature.csv not found, skipping upload"
          fi
          if [[ -f "./fact_indoor_humidity.csv" ]]; then
              rclone copy ./fact_indoor_humidity.csv sm2drive:Indoor/Model/
          else
              echo "fact_indoor_humidity.csv not found, skipping upload"
          fi

      - run: ls -l ${{ github.workspace }}/docs

      - run: git status

      - name: Commit files
        run: |
          git config --local user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git add --all :/
          git commit -m "Add docs"
        continue-on-error: true

      - name: Push changes
        uses: ad-m/github-push-action@master
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          branch: ${{ github.ref }}
        continue-on-error: true

      - run: |
          TIMESTAMP=$(date +"%Y-%m-%d_%H-%M-%S")
          if find ./latest -maxdepth 1 -type f -name 'Graph*' | grep -q .; then
            echo "ðŸ“‚ Soubory ThermoProSensor_export_* nalezeny, provÃ¡dÃ­m archivaci Vzduchotechnika/Latest/Upload"
            rclone copyto sm2drive:Vzduchotechnika/Latest/Upload sm2drive:Vzduchotechnika/Archiv/${TIMESTAMP}/
            rclone purge sm2drive:Vzduchotechnika/Latest/Upload && rclone mkdir sm2drive:Vzduchotechnika/Latest/Upload
          fi
          if find ./latest -maxdepth 1 -type f -name 'ThermoProSensor_export_*' | grep -q .; then
            echo "ðŸ“‚ Soubory Graph* nalezeny, provÃ¡dÃ­m archivaci Indoor/Latest/Upload"
            rclone copyto sm2drive:Indoor/Latest/Upload sm2drive:Indoor/Archiv/${TIMESTAMP}/
            rclone purge sm2drive:Indoor/Latest/Upload && rclone mkdir sm2drive:Indoor/Latest/Upload
          fi
